{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of segmentation to btrack to napari visualization\n",
    "\n",
    "This example uses TIF files saved out from segmentation using *stardist3D*, although will work for other segmentation pipelines too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import btrack\n",
    "import imageio\n",
    "import napari\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/media/quantumjot/Data/Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 1 - using a numpy array\n",
    "\n",
    "In this example, each image from the timelapse is a 3D volume (32 x 1200 x 1200) and there are 11 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_arr(path):\n",
    "    \"\"\"Segmentation as numpy array.\"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "    \n",
    "    for filename in files:\n",
    "        print(filename)\n",
    "        \n",
    "        # note, change this to imageio.imread for 2D data\n",
    "        img = imageio.volread(os.path.join(path, filename))\n",
    "        stack.append(img)\n",
    "        \n",
    "    return np.stack(stack, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_0.tif\n",
      "labels_1.tif\n",
      "labels_2.tif\n",
      "labels_3.tif\n",
      "labels_4.tif\n",
      "labels_5.tif\n",
      "labels_6.tif\n",
      "labels_7.tif\n",
      "labels_8.tif\n",
      "labels_9.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 32, 1200, 1200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack = segmentation_arr(PATH)\n",
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - using a generator\n",
    "\n",
    "This is useful if you're resource constrained and don't want to load all of the image data, or they are stored in an unusual format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_generator(path):\n",
    "    \"\"\"Segmentation generator\"\"\"\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "    \n",
    "    for filename in files:\n",
    "        \n",
    "        # note, change this to imageio.imread for 2D data\n",
    "        img = imageio.volread(os.path.join(path, filename))\n",
    "        \n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = segmentation_generator(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## localizing the objects\n",
    "\n",
    "Now we use a utility function to localise the objects in the segmentation, and also apply anisotropic scaling (using the `scale` option, here the z-values are scaled by 10x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/04/16 03:02:38 PM] Localizing objects from segmentation...\n",
      "[INFO][2021/04/16 03:03:06 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2021/04/16 03:03:06 PM] Found 11625 objects in 10 frames...\n"
     ]
    }
   ],
   "source": [
    "obj_from_arr = btrack.utils.segmentation_to_objects(stack, scale=(2., 1., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>939.055033</td>\n",
       "      <td>20.643012</td>\n",
       "      <td>12.771904</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 939.0550325850833, 'y': 20.643012309920348, 'z': 12.771904417089067, 't': 0, 'dummy': False, 'states': 0, 'label': 5, 'prob': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first object\n",
    "obj_from_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/04/16 03:03:07 PM] Localizing objects from segmentation...\n",
      "[INFO][2021/04/16 03:03:35 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2021/04/16 03:03:36 PM] Found 11625 objects in 10 frames...\n"
     ]
    }
   ],
   "source": [
    "obj_from_generator = btrack.utils.segmentation_to_objects(generator, scale=(2., 1., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>939.055033</td>\n",
       "      <td>20.643012</td>\n",
       "      <td>12.771904</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 939.0550325850833, 'y': 20.643012309920348, 'z': 12.771904417089067, 't': 0, 'dummy': False, 'states': 0, 'label': 5, 'prob': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first object\n",
    "obj_from_generator[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run btrack with the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/04/16 03:03:36 PM] Loaded btrack: /home/quantumjot/Dropbox/Code/py3/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2021/04/16 03:03:36 PM] btrack (v0.4.1) library imported\n",
      "[INFO][2021/04/16 03:03:36 PM] Setting max XYZ search radius to: 100\n",
      "[INFO][2021/04/16 03:03:36 PM] Starting BayesianTracker session\n",
      "[INFO][2021/04/16 03:03:36 PM] Loading configuration file: ../models/cell_config.json\n",
      "[INFO][2021/04/16 03:03:36 PM] Loading motion model: b'cell_motion'\n",
      "[INFO][2021/04/16 03:03:36 PM] Setting max XYZ search radius to: 10\n",
      "[INFO][2021/04/16 03:03:36 PM] Objects are of type: <class 'list'>\n",
      "[INFO][2021/04/16 03:03:36 PM] Set volume to ((0, 1200), (0, 1200), (-100000.0, 64.0))\n",
      "[INFO][2021/04/16 03:03:36 PM] Starting tracking... \n",
      "[INFO][2021/04/16 03:03:37 PM] Tracking objects in frames 0 to 10 (of 10)...\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Timing (Bayesian updates: 881.68ms, Linking: 8.44ms)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Probabilities (Link: 1.00000, Lost: 0.50195)\n",
      "[INFO][2021/04/16 03:03:44 PM] SUCCESS.\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Found 1726 tracks in 10 frames (in 0.0s)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Inserted 249 dummy objects to fill tracking gaps\n",
      "[INFO][2021/04/16 03:03:44 PM] Loading hypothesis model: cell_hypothesis\n",
      "[INFO][2021/04/16 03:03:44 PM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2021/04/16 03:03:44 PM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2021/04/16 03:03:44 PM] Optimizing...\n",
      "[INFO][2021/04/16 03:03:44 PM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.FALSE_POSITIVE: 346 (of 1726)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.LINK: 109 (of 332)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.DIVIDE: 29 (of 111)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.INITIALIZE_BORDER: 23 (of 49)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.INITIALIZE_FRONT: 1141 (of 1426)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.INITIALIZE_LAZY: 49 (of 251)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.TERMINATE_BORDER: 30 (of 55)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.TERMINATE_BACK: 1147 (of 1321)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - Fates.TERMINATE_LAZY: 65 (of 350)\n",
      "[INFO][2021/04/16 03:03:44 PM]  - TOTAL: 5621 hypotheses\n",
      "[INFO][2021/04/16 03:03:44 PM] Completed optimization with 1617 tracks\n",
      "[INFO][2021/04/16 03:03:44 PM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file('../models/cell_config.json')\n",
    "    tracker.max_search_radius = 10\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(obj_from_generator)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1200), (-1e5, 64.))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "#     tracker.export('./test3.hdf5', obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=3)\n",
    "    \n",
    "    tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize with napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tracks layer 'Tracks' at 0x7f1ce0413a10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(stack, scale=(1., 2., 1., 1.), name='Segmentation')\n",
    "viewer.add_tracks(data, properties=properties, graph=graph, name='Tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:napari]",
   "language": "python",
   "name": "conda-env-napari-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
