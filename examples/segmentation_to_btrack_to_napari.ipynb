{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of segmentation to btrack to napari visualization\n",
    "\n",
    "This example uses TIF files saved out from segmentation using *stardist3D*, although will work for other segmentation pipelines too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import btrack\n",
    "import imageio\n",
    "import napari\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/media/quantumjot/Data/Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 1 - using a numpy array\n",
    "\n",
    "In this example, each image from the timelapse is a 3D volume (32 x 1200 x 1200) and there are 10 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_arr(path):\n",
    "    \"\"\"Segmentation as numpy array.\"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "    \n",
    "    for filename in files:\n",
    "        print(filename)\n",
    "        \n",
    "        # note, change this to imageio.imread for 2D data\n",
    "        img = imageio.volread(os.path.join(path, filename))\n",
    "        stack.append(img)\n",
    "        \n",
    "    return np.stack(stack, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_0.tif\n",
      "labels_1.tif\n",
      "labels_2.tif\n",
      "labels_3.tif\n",
      "labels_4.tif\n",
      "labels_5.tif\n",
      "labels_6.tif\n",
      "labels_7.tif\n",
      "labels_8.tif\n",
      "labels_9.tif\n"
     ]
    }
   ],
   "source": [
    "stack = segmentation_arr(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print out the shape of the stack (T, Z, Y, X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 1200, 1200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - using a generator\n",
    "\n",
    "This is useful if you're resource constrained and don't want to load all of the image data, or they are stored in an unusual format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_generator(path):\n",
    "    \"\"\"Segmentation generator\"\"\"\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "    \n",
    "    for filename in files:\n",
    "        \n",
    "        # note, change this to imageio.imread for 2D data\n",
    "        img = imageio.volread(os.path.join(path, filename))\n",
    "        \n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = segmentation_generator(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## localizing the objects\n",
    "\n",
    "Now we use a utility function to localise the objects in the segmentation, and also apply anisotropic scaling (using the `scale` option, here the z-values are scaled by 2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/04/19 12:46:47 PM] Localizing objects from segmentation...\n",
      "[INFO][2021/04/19 12:46:53 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2021/04/19 12:46:53 PM] ...Found 11625 objects in 10 frames.\n"
     ]
    }
   ],
   "source": [
    "obj_from_arr = btrack.utils.segmentation_to_objects(stack, properties=('area', ), scale=(2., 1., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 939.0, 'y': 20.0, 'z': 12.0, 't': 0, 'dummy': False, 'states': 0, 'label': 5, 'prob': 0.0, 'area': 1381}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first object\n",
    "obj_from_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/04/19 12:46:53 PM] Localizing objects from segmentation...\n"
     ]
    }
   ],
   "source": [
    "obj_from_generator = btrack.utils.segmentation_to_objects(\n",
    "    generator, \n",
    "    properties = ('area', 'major_axis_length'), \n",
    "    scale=(2., 1., 1.)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the first object\n",
    "obj_from_generator[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run btrack with the objects\n",
    "\n",
    "We will use the objects from the generator here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file('../models/cell_config.json')\n",
    "    tracker.max_search_radius = 10\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(obj_from_generator)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1200), (-1e5, 64.))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export(os.path.join(PATH, 'tracking.h5'), obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=3)\n",
    "    \n",
    "    tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize with napari\n",
    "\n",
    "Note that we also set the scale of the images here to account for the anisotropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(stack, scale=(1., 2., 1., 1.), name='Segmentation')\n",
    "viewer.add_tracks(data, properties=properties, graph=graph, name='Tracks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:napari]",
   "language": "python",
   "name": "conda-env-napari-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
